{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbedc56-31fd-4055-91f3-1a368b17b141",
   "metadata": {},
   "source": [
    "# 朴素贝叶斯 \n",
    "此代码来自 阿里天池：https://tianchi.aliyun.com/notebook/192338  推荐自学 \n",
    "\n",
    "## 1 朴素贝叶斯\n",
    "\n",
    "### 1.1 贝叶斯公式\n",
    "\n",
    "贝叶斯公式是英国数学家提出的一个数据公式:\n",
    "\n",
    "$$\n",
    "p(A|B)=\\frac{p(A,B)}{p(B)}=\\frac{p(B|A) \\cdot p(A)}{\\sum_{a \\in ℱ_A}p(B|a) \\cdot p(a)}\n",
    "$$\n",
    "\n",
    "- p(A,B)：表示事件A和事件B同时发生的概率。\n",
    "\n",
    "- p(B)：表示事件B发生的概率，叫做先验概率；\n",
    "\n",
    "- p(A)：表示事件A发生的概率。\n",
    "\n",
    "- p(A|B)：表示当事件B发生的条件下，事件A发生的概率叫做后验概率。\n",
    "\n",
    "- p(B|A)：表示当事件A发生的条件下，事件B发生的概率。   \n",
    "\n",
    "### 1.2 朴素贝叶斯算法 \n",
    "\n",
    "朴素贝叶斯法 = 贝叶斯定理 + 特征条件独立。  \n",
    "\n",
    "贝叶斯法一定要计算两个概率：条件概率：$P(X^{(i)}=x^{(i)}|Y=c_k)$和类$c_k$的先验概率：$P(Y=c_k)$。 \n",
    "\n",
    "$$P(Y=c_k|X=x)=\\frac{\\prod_{i=1}^{n} P(x_i | Y=c_k)P(Y=c_k)}{\\sum_{k}\\prod_{i=1}^{n} P(x_i | Y=c_k)P(Y=c_k)}$$\n",
    "\n",
    "我们为了选择后验概率最大的结果，进行概率的比较，由于分母一致，这里直接去掉分母，得到最后的计算公式。\n",
    "\n",
    "$$\n",
    "y=arg max_{c_k}P(Y=c_k)\\prod_{j}P(X^{(j)}=x^{(j)}|Y=c_k)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d3ed5c-766a-45c9-9e43-4dc7bea861bd",
   "metadata": {},
   "source": [
    "## 2 朴素贝叶斯-鸢尾花数据集分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a643049-1713-47ad-884f-747ee9ee866a",
   "metadata": {},
   "source": [
    "**Step1: 库函数导入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8147eeeb-5f90-47e1-9258-f587fdb7c457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "# 加载莺尾花数据集\n",
    "from sklearn import datasets\n",
    "# 导入高斯朴素贝叶斯分类器\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d395bd-c2e9-47fc-92b2-5b6048926b11",
   "metadata": {},
   "source": [
    "**Step2: 数据导入&分析**\n",
    "\n",
    "我们需要计算两个概率分别是：\n",
    "\n",
    "- 条件概率：$P(X^{(i)}=x^{(i)}|Y=c_k)$\n",
    "\n",
    "- 类$c_k$的先验概率：$P(Y=c_k)$。\n",
    "\n",
    "通过分析发现训练数据是数值类型的数据，这里假设每个特征服从高斯分布，因此我们选择高斯朴素贝叶斯来进行分类计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c91253-24ce-41ff-9f31-cae05e849809",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bfc7c1-32db-4c50-a448-1dcdde2605fd",
   "metadata": {},
   "source": [
    "**Step3: 模型训练**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6487b3e1-9865-4aef-b006-8bcd89884a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB(var_smoothing=1e-08)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB(var_smoothing=1e-08)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB(var_smoothing=1e-08)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用高斯朴素贝叶斯进行计算\n",
    "clf = GaussianNB(var_smoothing=1e-8)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4c20ee-42c0-4f1f-96e0-285d2d76aa43",
   "metadata": {},
   "source": [
    "**Step4: 模型预测**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c58668-7a31-43d5-9988-1f446ea3cec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc : 1.000\n",
      "[2]\n",
      "预计的概率值: [[2.57698140e-197 1.75975179e-005 9.99982402e-001]]\n"
     ]
    }
   ],
   "source": [
    "# 评估\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = np.sum(y_test == y_pred) / X_test.shape[0]\n",
    "print(\"Test Acc : %.3f\" % acc)\n",
    "\n",
    "# 预测\n",
    "y_proba = clf.predict_proba(X_test[:1])\n",
    "print(clf.predict(X_test[:1]))\n",
    "print(\"预计的概率值:\", y_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9216125d-2e10-43ba-865b-32204134d60a",
   "metadata": {},
   "source": [
    "**Step5: 原理简析** \n",
    "\n",
    "高斯朴素贝叶斯假设每个特征都服从高斯分布，我们把一个随机变量X服从数学期望为μ，方差为σ^2的数据分布称为高斯分布。对于每个特征我们一般使用平均值来估计μ和使用所有特征的方差估计σ^2。\n",
    "\n",
    "$$\n",
    "P(X^{(i)}=x^{(i)}|Y=c_k) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x^{(i)} - \\mu_{c_k})^2}{2\\sigma^2_{c_k}}\\right)\n",
    "$$\n",
    "\n",
    "从上述例子中的预测结果中，我们可以看到类别2对应的后验概率值最大，所以我们认为类别2是最优的结果。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f145f7ac-5bd1-4429-b18b-9993776d6b9b",
   "metadata": {},
   "source": [
    "## 1.3 朴素贝叶斯-新闻分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09be346f-5888-403a-b3b2-39e3a155deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "news=fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104e2300-6d00-4344-9e02-8edd279dd692",
   "metadata": {},
   "source": [
    "如果存在下载速度慢或者出现网络报错问题，\n",
    "\n",
    "请参照[博客](https://blog.csdn.net/weixin_45170058/article/details/102566934?spm=1001.2101.3001.6650.1&utm_medium=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-102566934-blog-88700782.pc_relevant_default&depth_1-utm_source=distribute.pc_relevant.none-task-blog-2%7Edefault%7ECTRLIST%7ERate-1-102566934-blog-88700782.pc_relevant_default&utm_relevant_index=2)教程自行解决。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67e7f09-72e4-42d9-bf82-386e4c6dd3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行数据分割\n",
    "x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25)\n",
    "# 对数据集进行特征抽取\n",
    "tf = TfidfVectorizer()\n",
    "# 以训练集当中的词的列表进行每篇文章重要性统计['a','b','c','d']\n",
    "x_train = tf.fit_transform(x_train)\n",
    "x_test = tf.transform(x_test)\n",
    "\n",
    "# 进行朴素贝叶斯算法的预测\n",
    "mlt = MultinomialNB(alpha=1.0)\n",
    "print(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66fceed7-3d85-46fb-b35f-f76fd17626c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的文章类别为： [10 10 17 ...  3 12 16]\n",
      "准确率为： 0.8578098471986417\n",
      "每个类别的精确率和召回率：                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.85      0.68      0.76       197\n",
      "           comp.graphics       0.87      0.81      0.84       232\n",
      " comp.os.ms-windows.misc       0.88      0.86      0.87       242\n",
      "comp.sys.ibm.pc.hardware       0.76      0.87      0.81       228\n",
      "   comp.sys.mac.hardware       0.86      0.90      0.88       209\n",
      "          comp.windows.x       0.91      0.85      0.88       242\n",
      "            misc.forsale       0.93      0.63      0.75       244\n",
      "               rec.autos       0.90      0.89      0.89       268\n",
      "         rec.motorcycles       0.94      0.95      0.95       255\n",
      "      rec.sport.baseball       0.98      0.95      0.96       266\n",
      "        rec.sport.hockey       0.94      0.98      0.96       258\n",
      "               sci.crypt       0.85      0.98      0.91       269\n",
      "         sci.electronics       0.91      0.80      0.85       251\n",
      "                 sci.med       0.96      0.88      0.92       257\n",
      "               sci.space       0.90      0.95      0.92       248\n",
      "  soc.religion.christian       0.53      1.00      0.69       239\n",
      "      talk.politics.guns       0.74      0.99      0.85       214\n",
      "   talk.politics.mideast       0.97      0.96      0.96       257\n",
      "      talk.politics.misc       0.98      0.68      0.80       184\n",
      "      talk.religion.misc       0.94      0.22      0.35       152\n",
      "\n",
      "                accuracy                           0.86      4712\n",
      "               macro avg       0.88      0.84      0.84      4712\n",
      "            weighted avg       0.88      0.86      0.85      4712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mlt.fit(x_train, y_train)   #MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "y_predict = mlt.predict(x_test)\n",
    "print(\"预测的文章类别为：\", y_predict)\n",
    "#预测的文章类别为： [ 3 16  5 ...  0  5  8]\n",
    "# 得出准确率\n",
    "print(\"准确率为：\", mlt.score(x_test, y_test))\n",
    "#准确率为： 0.8414685908319185\n",
    "print(\"每个类别的精确率和召回率：\", classification_report(y_test, y_predict, target_names=news.target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bcb41-c5cc-477e-855d-ed07de62f6de",
   "metadata": {},
   "source": [
    "## 4 朴素贝叶斯算法的优缺点\n",
    "\n",
    "优点：\n",
    "- （1）朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。\n",
    "- （2） 分类准确度高，速度快\n",
    "- （3）对缺失数据不太敏感，算法也比较简单，常用于文本分类，如垃圾邮件的分类，信用评估，钓鱼网站检测等。。\n",
    "\n",
    "缺点：\n",
    "- （1）理论上，朴素贝叶斯模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为朴素贝叶斯模型给定输出类别的情况下,假设属性之间相互独立，这个假设在实际应用中往往是不成立的。\n",
    "    - 在属性个数比较多或者属性之间相关性较大时，分类效果不好。\n",
    "    - 而在属性相关性较小时，朴素贝叶斯性能最为良好。\n",
    "- （2）需要知道先验概率，且先验概率很多时候取决于假设，假设的模型可以有很多种，有时会由于假设的先验模型的原因导致预测效果不佳。\n",
    "- （3）由于我们是通过先验和数据来决定后验的概率从而决定分类，所以分类决策存在一定的错误率。\n",
    "- （4）对输入数据的表达形式很敏感。\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
